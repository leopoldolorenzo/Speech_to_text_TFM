# verificar_tokenizer.py
# Verifica que el tokenizer y el modelo est√©n correctamente alineados

import os
from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC

# === Configuraci√≥n ===
TOKENIZER_DIR = "models/tokenizer_v1_nospecial"
MODEL_PATH = "models/fine_tune_02"  # Cambia si usas otro modelo

print(f"üì¶ Cargando processor desde: {TOKENIZER_DIR}")
processor = Wav2Vec2Processor.from_pretrained(TOKENIZER_DIR)
vocab = processor.tokenizer.get_vocab()

print("üî§ Tokens en vocabulario:", len(vocab))
print("üî£ Tokens especiales:")
print(" - pad_token:", repr(processor.tokenizer.pad_token))
print(" - bos_token:", repr(processor.tokenizer.bos_token))
print(" - eos_token:", repr(processor.tokenizer.eos_token))

if os.path.exists(MODEL_PATH):
    print(f"\nüß† Cargando modelo desde: {MODEL_PATH}")
    model = Wav2Vec2ForCTC.from_pretrained(MODEL_PATH)
    lm_head_size = model.lm_head.out_features
    print(f"üîé lm_head.out_features = {lm_head_size}")

    if lm_head_size != len(vocab):
        print("‚ùå ERROR: El vocabulario y el lm_head tienen diferente tama√±o!")
    else:
        print("‚úÖ Tama√±os coinciden. Modelo y tokenizer alineados.")
else:
    print("‚ö†Ô∏è No se ha encontrado el modelo en disco. Solo se verific√≥ el tokenizer.")