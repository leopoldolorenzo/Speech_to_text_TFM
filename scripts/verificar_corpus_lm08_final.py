#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
verificar_corpus_lm08_final.py

üìå Verifica que el corpus_lm08_total.txt:
‚Ä¢ Solo contiene los 41 tokens del tokenizer.
‚Ä¢ Los tokens est√°n en el orden y posici√≥n correctos.
‚Ä¢ Todas las l√≠neas est√°n correctamente normalizadas.
"""

import json
from pathlib import Path
import unicodedata

VOCAB_PATH = Path("models/tokenizer_v2_base41/vocab.json")
CORPUS_PATH = Path("data/lm/corpus_lm08_total.txt")

# Tokens esperados (en orden)
TOKENS_ESPERADOS = [
    "<pad>", "<s>", "</s>", "<unk>", "|", "'", "-", "a", "b", "c", "d", "e", "f", "g", "h",
    "i", "j", "k", "l", "m", "n", "o", "p", "q", "r", "s", "t", "u", "v", "w", "x", "y", "z",
    "√°", "√©", "√≠", "√±", "√≥", "√∂", "√∫", "√º"
]

# --- Verificaci√≥n del vocabulario ---
with open(VOCAB_PATH, 'r', encoding='utf-8') as f:
    vocab = json.load(f)

tokens_actuales = [token for token, idx in sorted(vocab.items(), key=lambda x: x[1])]

print("üì¶ Verificando orden y contenido del vocabulario‚Ä¶")
if tokens_actuales != TOKENS_ESPERADOS:
    print("‚ùå El vocabulario NO coincide con el esperado.\n")
    set_actual = set(tokens_actuales)
    set_esperado = set(TOKENS_ESPERADOS)

    faltan = set_esperado - set_actual
    sobran = set_actual - set_esperado

    if faltan:
        print(f"‚ùå FALTAN tokens: {faltan}")
    if sobran:
        print(f"‚ùå SOBRAN tokens: {sobran}")

    desordenados = [(i, t, a) for i, (t, a) in enumerate(zip(TOKENS_ESPERADOS, tokens_actuales)) if t != a]
    if desordenados:
        print("\n‚ùó Tokens en orden incorrecto:")
        for i, esperado, actual in desordenados:
            print(f"  Posici√≥n {i}: esperado='{esperado}' ‚â† actual='{actual}'")

    exit(1)
else:
    print("‚úÖ Vocabulario correcto (41 tokens en orden)\n")

# --- Verificaci√≥n del corpus ---
print(f"üìñ Verificando l√≠neas en: {CORPUS_PATH} ‚Ä¶")
fuera_vocab = {}
lineas_invalidas = 0
total = 0

caracteres_validos = set(tokens_actuales)

with CORPUS_PATH.open(encoding="utf-8") as f:
    for n, linea in enumerate(f, 1):
        total += 1
        linea = unicodedata.normalize("NFC", linea.strip())
        if not linea:
            continue
        for c in linea:
            if c not in caracteres_validos:
                fuera_vocab[c] = fuera_vocab.get(c, 0) + 1
                lineas_invalidas += 1
                break

print(f"\nüìä Resultado:")
print(f"  L√≠neas totales analizadas : {total:,}")
print(f"  L√≠neas inv√°lidas (OOV)    : {lineas_invalidas:,}")
if fuera_vocab:
    print("\n‚ùó Caracteres fuera del vocabulario:")
    for char, freq in sorted(fuera_vocab.items(), key=lambda x: -x[1])[:20]:
        nombre = unicodedata.name(char, "UNKNOWN")
        print(f"  '{char}' (U+{ord(char):04X}) ‚Äî {freq} veces ‚Äî {nombre}")
else:
    print("‚úÖ Todas las l√≠neas est√°n dentro del vocabulario.")

