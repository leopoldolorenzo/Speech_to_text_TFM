Perfecto. AquÃ­ tenÃ©s el `README.md` actualizado con:

* El **nombre oficial del proyecto**: `tfm_asr2025`
* Los **nombres completos de los tres autores**
* Todo el contenido tÃ©cnico organizado y listo para dejarlo en el repositorio

---

### âœ… `README.md` final para `tfm_asr2025`

```markdown
# ðŸ§  tfm_asr2025 â€“ Fine-tuning de Wav2Vec2 en EspaÃ±ol con Common Voice y Modelo de Lenguaje

Este proyecto implementa un pipeline completo de **reconocimiento automÃ¡tico del habla (ASR)** en espaÃ±ol mediante **fine-tuning del modelo Wav2Vec2.0** sobre el dataset **Common Voice**. AdemÃ¡s, se incorpora un **modelo de lenguaje externo (KenLM)** para mejorar la decodificaciÃ³n usando `pyctcdecode`.

> Trabajo Fin de MÃ¡ster â€“ MÃ¡ster en Inteligencia Artificial (UNIR)  
> Proyecto colaborativo de investigaciÃ³n aplicada sobre ASR en espaÃ±ol.

---

## ðŸ‘¥ Autores

- **Leopoldo Lorenzo FernÃ¡ndez**
- **JosÃ© Navacerrada Santiago**
- **Rafael FernÃ¡ndez Pedroche**

---

## ðŸ“ Estructura del proyecto

```

TFM/
â”œâ”€â”€ data/                  # Dataset, corpus LM, audios de prueba
â”œâ”€â”€ models/                # Modelos entrenados y tokenizer
â”œâ”€â”€ training/              # Checkpoints durante el entrenamiento
â”œâ”€â”€ logs/                  # Logs de entrenamiento (TensorBoard)
â”œâ”€â”€ scripts/               # Scripts para preprocesamiento, entrenamiento, evaluaciÃ³n
â”œâ”€â”€ tools/                 # KenLM compilado y utilitarios
â”œâ”€â”€ notebooks/             # Visualizaciones o pruebas exploratorias
â”œâ”€â”€ requirements.txt       # Requisitos mÃ­nimos de Python
â”œâ”€â”€ environment.yml        # Entorno Conda/Mamba completo
â””â”€â”€ README.md              # Este archivo

````

---

## ðŸ§ª Requisitos del entorno

### ðŸ Crear entorno con Mamba o Conda

```bash
mamba create -n asr_env python=3.10 -y
mamba activate asr_env
mamba install -c conda-forge --file requirements.txt
````

> Alternativamente:
> `conda env create -f environment.yml`

---

## ðŸš€ Pipeline de entrenamiento

1. **Preparar muestra de entrenamiento:**

```bash
python scripts/convertir_y_preparar_muestra_1.py
```

2. **Generar dataset compatible con HuggingFace:**

```bash
python scripts/generar_dataset_finetune_01.py
```

3. **Verificaciones previas:**

```bash
python scripts/verificar_dataset_entrenamiento.py
python scripts/verificar_cobertura_vocabulario.py
python scripts/verificar_tokenizer.py
```

4. **Entrenamiento principal:**

```bash
python scripts/entrenar_finetune_01.py
```

5. **Prueba de inferencia:**

```bash
python scripts/verificar_modelo_finetune.py
```

---

## ðŸ§  Modelo de Lenguaje (KenLM)

1. **Generar LM adaptado al vocabulario del modelo ASR:**

```bash
python scripts/generar_lm_finetune.py
```

Esto genera:

```
data/lm/modelo_finetune.arpa
data/lm/modelo_finetune.bin
```

2. **Uso con pyctcdecode para mejorar la transcripciÃ³n.**

---

## ðŸ” EvaluaciÃ³n comparativa

* **Sin modelo de lenguaje:**

```bash
python scripts/comparar_modelos_base_vs_finetune.py
```

* **Con modelo de lenguaje dedicado:**

```bash
python scripts/comparar_modelos_con_lm_dedicado.py
```

> El modelo base usa `modelo_limpio.bin`
> El modelo fine-tuneado usa `modelo_finetune.bin`

---

## ðŸ”‘ Licencia

Este proyecto es de uso **acadÃ©mico y educativo**.
Incluye Ãºnicamente datos pÃºblicos: Mozilla Common Voice y Hugging Face.

---

## ðŸ“¦ Repositorio remoto

El repositorio se aloja de forma privada en NAS Synology:

```
ssh://leo@192.168.0.5:/volume2/Git/tfm_asr2025.git
```

```

---
