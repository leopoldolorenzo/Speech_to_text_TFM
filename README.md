Perfecto, aquÃ­ tienes:

---

## ğŸ“ Archivos a crear

- `~/TFM/.gitignore`
- `~/TFM/README.md`

---

## âœ… `.gitignore` completo

Crea el archivo `~/TFM/.gitignore` con este contenido:

```gitignore
# === ENTORNOS ===
.env
.venv/
__pycache__/
*.pyc

# === MODELOS PESADOS ===
models/*
!models/base/  # permite base si es ligero

# === AUDIOS ===
audios/**/*.wav

# === LOGITS y SALIDAS ===
outputs/**
results/**/*.csv

# === LENGUAJE Y CORPUS ===
data/lm/*.txt
data/lm/*.arpa
data/lm/*.bin

# === ARCHIVOS BINARIOS O GRANDES ===
*.npy
*.bin
*.pt
*.pkl
*.zip
*.gz
```

---

## ğŸ“ `README.md` completo

Guarda esto como `~/TFM/README.md`:

```markdown
# ğŸ§  Proyecto ASR - TranscripciÃ³n de voz a texto en EspaÃ±ol

Este proyecto implementa un sistema de reconocimiento automÃ¡tico del habla (ASR) utilizando **Wav2Vec2.0**, **KenLM** y decodificaciÃ³n con modelo de lenguaje (LM) para mejorar la precisiÃ³n de las transcripciones.

---

## ğŸ“‚ Estructura del proyecto

```bash
TFM/
â”œâ”€â”€ audios/                  # Audios originales y convertidos (.wav)
â”‚   â””â”€â”€ convertidos/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ vocab/               # vocab.txt y lexicon.txt
â”‚   â”œâ”€â”€ lm/                  # Corpus y modelo de lenguaje (KenLM)
â”‚   â””â”€â”€ val_dataset.tsv      # Dataset de evaluaciÃ³n
â”œâ”€â”€ models/                  # Modelos base y fine-tuned (NO subidos por defecto)
â”œâ”€â”€ outputs/                 # Logits generados por los modelos
â”œâ”€â”€ results/                 # MÃ©tricas y transcripciones
â”œâ”€â”€ scripts/                 # Todos los scripts Python del sistema
â”œâ”€â”€ notebooks/               # (Opcional) anÃ¡lisis y visualizaciÃ³n
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸš€ CaracterÃ­sticas

- ğŸ“Œ Usa `Wav2Vec2.0` (modelo HuggingFace en espaÃ±ol)
- ğŸ“š Mejora con decodificaciÃ³n `beam search` + `KenLM`
- ğŸ” MÃ©tricas de calidad: **WER** y **CER**
- ğŸ” Soporte multimodelo (base + fine-tuned)
- ğŸ–¥ï¸ Scripts listos para:
  - Procesar audios (`pipeline_asr.py`)
  - Evaluar modelo (`evaluate_model.py`)
  - DecodificaciÃ³n con LM (`decode_with_lm.py`)
  - Extraer vocabulario y logits

---

## ğŸ› ï¸ Requisitos

- Python 3.10
- Conda / Mamba
- PyTorch
- HuggingFace Transformers
- Librosa, KenLM, jiwer

---

## â–¶ï¸ CÃ³mo empezar

```bash
# 1. Activar entorno
conda activate asr_env

# 2. Procesar un audio
python scripts/pipeline_asr.py audios/convertidos/prueba01.wav

# 3. Evaluar el sistema completo
python scripts/evaluate_model.py
```

---

## ğŸ§ª EvaluaciÃ³n

Calcula mÃ©tricas de calidad comparando las transcripciones reales con las predichas.

```bash
# Dataset de evaluaciÃ³n
data/val_dataset.tsv

# Resultado:
results/metrics.csv
```

---

## ğŸ“¦ CrÃ©ditos

- Modelo base: [`jonatasgrosman/wav2vec2-large-xlsr-53-spanish`](https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-spanish)
- Lenguaje: [`KenLM`](https://github.com/kpu/kenlm)
- TranscripciÃ³n: [`pyctcdecode`](https://github.com/kensho-technologies/pyctcdecode)

---

## ğŸ“Œ Nota

Este proyecto fue desarrollado para un Trabajo de Fin de MÃ¡ster (TFM). Puede extenderse con fine-tuning, nuevos datasets, mÃºltiples modelos y mejoras en el pipeline.

---
