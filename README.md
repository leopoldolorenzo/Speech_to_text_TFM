Â¡Perfecto! Te dejo a continuaciÃ³n un `README.md` completo, adaptado a tu proyecto de fine-tuning de modelos Wav2Vec2 con evaluaciÃ³n y uso de lenguaje externo (LM) en espaÃ±ol. Incluye:

- DescripciÃ³n del proyecto  
- Estructura del repositorio  
- Requisitos de entorno  
- Instrucciones de uso  
- Entrenamiento  
- EvaluaciÃ³n  
- Licencia  

---

### âœ… CONTENIDO PARA TU `README.md`

```markdown
# ğŸ§  Fine-tuning de Wav2Vec2 en EspaÃ±ol con Common Voice y Language Model (TFM)

Este proyecto implementa un pipeline completo para el **fine-tuning** del modelo `wav2vec2-large-xlsr-53-spanish` usando el dataset **Common Voice** en espaÃ±ol. AdemÃ¡s, incorpora un **modelo de lenguaje externo (KenLM)** para mejorar la decodificaciÃ³n.

> Trabajo Fin de MÃ¡ster â€“ Reconocimiento AutomÃ¡tico del Habla (ASR)

---

## ğŸ“ Estructura del proyecto

```
TFM/
â”œâ”€â”€ data/                  # Dataset, corpus LM, audios de prueba
â”œâ”€â”€ models/                # Modelos entrenados y tokenizer
â”œâ”€â”€ training/              # Checkpoints durante el entrenamiento
â”œâ”€â”€ logs/                  # Logs de entrenamiento
â”œâ”€â”€ scripts/               # Scripts para procesar, entrenar y evaluar
â”œâ”€â”€ tools/                 # KenLM compilado y otros utilitarios
â”œâ”€â”€ notebooks/             # (opcional) Visualizaciones o pruebas
â”œâ”€â”€ requirements.txt       # Requisitos de Python
â”œâ”€â”€ environment.yml        # Entorno Conda/Mamba
â””â”€â”€ README.md              # Este archivo
```

---

## ğŸ§ª Requisitos

### ğŸ Recomendado: crear entorno con Mamba o Conda

```bash
mamba create -n asr_env python=3.10 -y
mamba activate asr_env
mamba install -c conda-forge --file requirements.txt
```

> ğŸ’¡ TambiÃ©n podÃ©s usar: `conda env create -f environment.yml`

---

## ğŸš€ Entrenamiento paso a paso

1. **Convertir audios y preparar dataset:**

```bash
python scripts/convertir_y_preparar_muestra_1.py
```

2. **Generar dataset HF:**

```bash
python scripts/generar_dataset_finetune_01.py
```

3. **Verificar todo antes de entrenar:**

```bash
python scripts/verificar_dataset_entrenamiento.py
python scripts/verificar_cobertura_vocabulario.py
python scripts/verificar_tokenizer.py
```

4. **Lanzar entrenamiento:**

```bash
python scripts/entrenar_finetune_01.py
```

5. **Probar el modelo entrenado:**

```bash
python scripts/verificar_modelo_finetune.py
```

---

## ğŸ§  Modelo de Lenguaje (KenLM)

### Crear un LM adaptado al vocabulario del modelo fine-tuneado:

```bash
python scripts/generar_lm_finetune.py
```

Esto genera:

```
data/lm/modelo_finetune.arpa
data/lm/modelo_finetune.bin
```

---

## ğŸ” EvaluaciÃ³n y comparaciÃ³n

### Comparar base vs fine-tune sin LM:

```bash
python scripts/comparar_modelos_base_vs_finetune.py
```

### Comparar ambos con su LM respectivo:

```bash
python scripts/comparar_modelos_con_lm_dedicado.py
```

> El modelo base usa `modelo_limpio.bin` y el fine-tune usa `modelo_finetune.bin`.

---

## ğŸ”‘ Licencia

Este proyecto es solo para **uso acadÃ©mico** y estÃ¡ basado en datos pÃºblicos (Common Voice, HuggingFace).

---

## âœï¸ Autor

**Rafael FERNÃNDEZ PEDROCHE**
**JosÃ© NAVACERRADA SANTIAGO**
**Leopoldo LORENZO FERNÃNDEZ**

MÃ¡ster en Inteligencia Artificial  
UNIR
```

---

Â¿QuerÃ©s que lo guarde como archivo directamente en tu proyecto? Â¿O lo copias vos?