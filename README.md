
# ğŸ§  tfm_asr2025 â€“ Fine-tuning de Wav2Vec2 en EspaÃ±ol con Common Voice y Modelo de Lenguaje

Este proyecto implementa un pipeline completo de **reconocimiento automÃ¡tico del habla (ASR)** en espaÃ±ol mediante **fine-tuning del modelo Wav2Vec2.0** sobre el dataset **Common Voice**. AdemÃ¡s, se incorpora un **modelo de lenguaje externo (KenLM)** para mejorar la decodificaciÃ³n usando `pyctcdecode`. El sistema se complementa con **diarizaciÃ³n de hablantes (PyAnnote.audio)** y **traducciÃ³n automÃ¡tica local (Helsinki-NLP)**.

> Trabajo Fin de MÃ¡ster â€“ MÃ¡ster en Inteligencia Artificial (UNIR)  
> Proyecto colaborativo de investigaciÃ³n aplicada sobre ASR en espaÃ±ol.

---

## ğŸ‘¥ Autores

- **Leopoldo Lorenzo FernÃ¡ndez**
- **JosÃ© Fernando Navacerrada Santiago**
- **Rafael FernÃ¡ndez Pedroche**

---

## ğŸ“ Estructura del proyecto

```
TFM/
â”œâ”€â”€ data/                  # Dataset, corpus LM, audios de prueba
â”œâ”€â”€ models/                # Modelos entrenados y tokenizer
â”œâ”€â”€ training/              # Checkpoints durante el entrenamiento
â”œâ”€â”€ logs/                  # Logs de entrenamiento (TensorBoard / W&B)
â”œâ”€â”€ scripts/               # Scripts para preprocesamiento, entrenamiento, evaluaciÃ³n
â”œâ”€â”€ tools/                 # KenLM compilado, pyctcdecode y utilitarios
â”œâ”€â”€ notebooks/             # Visualizaciones o pruebas exploratorias
â”œâ”€â”€ frontend/              # Interfaz React para transcripciÃ³n y visualizaciÃ³n
â”œâ”€â”€ backend/               # API FastAPI para inferencia y control del pipeline
â”œâ”€â”€ requirements.txt       # Requisitos mÃ­nimos de Python
â”œâ”€â”€ environment.yml        # Entorno Conda/Mamba completo
â””â”€â”€ README.md              # Este archivo
```

---

## ğŸ§ª Requisitos del entorno

### ğŸ Crear entorno con Mamba o Conda

```bash
mamba create -n asr_env python=3.10 -y
mamba activate asr_env
mamba install -c conda-forge --file requirements.txt
```

> Alternativamente:  
> `conda env create -f environment.yml`

---

## ğŸš€ Pipeline de entrenamiento

1ï¸âƒ£ **Preparar muestra de entrenamiento:**
```bash
python scripts/convertir_y_preparar_muestra_1.py
```

2ï¸âƒ£ **Generar dataset compatible con HuggingFace:**
```bash
python scripts/generar_dataset_finetune_01.py
```

3ï¸âƒ£ **Verificaciones previas:**
```bash
python scripts/verificar_dataset_entrenamiento.py
python scripts/verificar_cobertura_vocabulario.py
python scripts/verificar_tokenizer.py
```

4ï¸âƒ£ **Entrenamiento principal:**
```bash
python scripts/entrenar_finetune_01.py
```

5ï¸âƒ£ **Prueba de inferencia:**
```bash
python scripts/verificar_modelo_finetune.py
```

---

## ğŸ§  Modelo de Lenguaje (KenLM)

1ï¸âƒ£ **Generar LM adaptado al vocabulario del modelo ASR:**
```bash
python scripts/generar_lm_finetune.py
```
Esto genera:
```
data/lm/modelo_finetune.arpa
data/lm/modelo_finetune.bin
```

2ï¸âƒ£ **Uso con pyctcdecode para mejorar la transcripciÃ³n.**

---

## ğŸ—£ï¸ DiarizaciÃ³n e identificaciÃ³n de hablantes

El pipeline integra `pyannote.audio` para segmentaciÃ³n y etiquetado de intervenciones:
- DetecciÃ³n de actividad de voz
- ExtracciÃ³n de embeddings
- Clustering jerÃ¡rquico para agrupar hablantes

Scripts principales:
```bash
python scripts/diarizacion_pipeline.py
```

---

## ğŸŒ TraducciÃ³n automÃ¡tica local

Se usa el modelo **Helsinki-NLP/opus-mt-es-en**:
```bash
python scripts/traducir_transcripcion.py
```

El modelo se descarga y guarda localmente en `models/opus-mt-es-en/`.

---

## ğŸ” EvaluaciÃ³n comparativa

âœ… **Sin modelo de lenguaje:**
```bash
python scripts/comparar_modelos_base_vs_finetune.py
```

âœ… **Con modelo de lenguaje dedicado:**
```bash
python scripts/comparar_modelos_con_lm_dedicado.py
```
> El modelo base usa `modelo_limpio.bin`  
> El modelo fine-tuneado usa `modelo_finetune.bin`

---

## ğŸ’» Frontend + API

ğŸ“Œ API FastAPI:
```bash
uvicorn backend.main:app --reload
```

ğŸ“Œ Frontend React:
```bash
cd frontend
npm install
npm start
```
La interfaz permite:
- Subir audios
- Visualizar transcripciones con colores por hablante
- Resaltado dinÃ¡mico durante la reproducciÃ³n

---

## ğŸ”‘ Licencia

Este proyecto es de uso **acadÃ©mico y educativo**.  
Incluye Ãºnicamente datos pÃºblicos: Mozilla Common Voice, OpenSubtitles, CC100, Hugging Face.

---
